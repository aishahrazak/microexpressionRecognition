{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RESNET-50\n",
    "\n",
    "### TRANSFER LEARNING\n",
    "1. Take layers from a previously trained model.\n",
    "2. Freeze them, so as to avoid destroying any of the information they contain during future training rounds.\n",
    "3. Add some new, trainable layers on top of the frozen layers. They will learn to turn the old features into predictions on a new dataset.\n",
    "4. Train the new layers on your dataset.\n",
    "5. Fine-tuning (optional), which consists of unfreezing the entire model you obtained above (or part of it), and re-training it on the new data with a very low learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "# CHECK INPUT IMAGE SHAPE\n",
    "import cv2\n",
    "input_path = r'C:\\Users\\User\\Documents\\UKM\\Project\\Dataset\\Consolidated Dataset\\organized'\n",
    "inp = input_path + '\\casme2-sub01_EP02_01f-happiness.jpg'\n",
    "img = cv2.imread(inp)\n",
    "print(img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 333 files belonging to 7 classes.\n",
      "Using 267 files for training.\n",
      "Found 333 files belonging to 7 classes.\n",
      "Using 66 files for validation.\n",
      "['anger', 'contempt', 'disgust', 'fear', 'happiness', 'sadness', 'surprise']\n"
     ]
    }
   ],
   "source": [
    "# CREATE TRAINING AND VALIDATION DATASET FROM MICRO_EXPRESION COMBINED DATASET\n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "\n",
    "ME_path = r\"C:\\Users\\User\\Documents\\UKM\\Project\\Dataset\\Consolidated Dataset\\organized\"\n",
    "me_train_dataset = image_dataset_from_directory(ME_path, labels='inferred', label_mode='int',\n",
    "                    validation_split=0.2, subset='training',\n",
    "                    seed=1234, image_size=(224,224), color_mode='rgb')\n",
    "me_val_dataset = image_dataset_from_directory(ME_path, labels='inferred', label_mode='int',\n",
    "                    validation_split=0.2, subset='validation',\n",
    "                    seed=1234, image_size=(224,224), color_mode='rgb')\n",
    "\n",
    "print(me_train_dataset.class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import Input, Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
    "from tensorflow.keras.metrics import CategoricalAccuracy\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"resnet50\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_12 (InputLayer)           [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)       (None, 230, 230, 3)  0           input_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1_conv (Conv2D)             (None, 112, 112, 64) 9472        conv1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1_bn (BatchNormalization)   (None, 112, 112, 64) 256         conv1_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1_relu (Activation)         (None, 112, 112, 64) 0           conv1_bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pad (ZeroPadding2D)       (None, 114, 114, 64) 0           conv1_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pool (MaxPooling2D)       (None, 56, 56, 64)   0           pool1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_conv (Conv2D)    (None, 56, 56, 64)   4160        pool1_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_relu (Activation (None, 56, 56, 64)   0           conv2_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_relu (Activation (None, 56, 56, 64)   0           conv2_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_conv (Conv2D)    (None, 56, 56, 256)  16640       pool1_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_add (Add)          (None, 56, 56, 256)  0           conv2_block1_0_bn[0][0]          \n",
      "                                                                 conv2_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_out (Activation)   (None, 56, 56, 256)  0           conv2_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_conv (Conv2D)    (None, 56, 56, 64)   16448       conv2_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_relu (Activation (None, 56, 56, 64)   0           conv2_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_relu (Activation (None, 56, 56, 64)   0           conv2_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_add (Add)          (None, 56, 56, 256)  0           conv2_block1_out[0][0]           \n",
      "                                                                 conv2_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_out (Activation)   (None, 56, 56, 256)  0           conv2_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_conv (Conv2D)    (None, 56, 56, 64)   16448       conv2_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_relu (Activation (None, 56, 56, 64)   0           conv2_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_relu (Activation (None, 56, 56, 64)   0           conv2_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_add (Add)          (None, 56, 56, 256)  0           conv2_block2_out[0][0]           \n",
      "                                                                 conv2_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_out (Activation)   (None, 56, 56, 256)  0           conv2_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_conv (Conv2D)    (None, 28, 28, 128)  32896       conv2_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_relu (Activation (None, 28, 28, 128)  0           conv3_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_relu (Activation (None, 28, 28, 128)  0           conv3_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_conv (Conv2D)    (None, 28, 28, 512)  131584      conv2_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_add (Add)          (None, 28, 28, 512)  0           conv3_block1_0_bn[0][0]          \n",
      "                                                                 conv3_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_out (Activation)   (None, 28, 28, 512)  0           conv3_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_relu (Activation (None, 28, 28, 128)  0           conv3_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_relu (Activation (None, 28, 28, 128)  0           conv3_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_add (Add)          (None, 28, 28, 512)  0           conv3_block1_out[0][0]           \n",
      "                                                                 conv3_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_out (Activation)   (None, 28, 28, 512)  0           conv3_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_relu (Activation (None, 28, 28, 128)  0           conv3_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_relu (Activation (None, 28, 28, 128)  0           conv3_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_add (Add)          (None, 28, 28, 512)  0           conv3_block2_out[0][0]           \n",
      "                                                                 conv3_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_out (Activation)   (None, 28, 28, 512)  0           conv3_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_relu (Activation (None, 28, 28, 128)  0           conv3_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_relu (Activation (None, 28, 28, 128)  0           conv3_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_add (Add)          (None, 28, 28, 512)  0           conv3_block3_out[0][0]           \n",
      "                                                                 conv3_block4_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_out (Activation)   (None, 28, 28, 512)  0           conv3_block4_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_conv (Conv2D)    (None, 14, 14, 256)  131328      conv3_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_relu (Activation (None, 14, 14, 256)  0           conv4_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_relu (Activation (None, 14, 14, 256)  0           conv4_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_conv (Conv2D)    (None, 14, 14, 1024) 525312      conv3_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_add (Add)          (None, 14, 14, 1024) 0           conv4_block1_0_bn[0][0]          \n",
      "                                                                 conv4_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_out (Activation)   (None, 14, 14, 1024) 0           conv4_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_relu (Activation (None, 14, 14, 256)  0           conv4_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_relu (Activation (None, 14, 14, 256)  0           conv4_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_add (Add)          (None, 14, 14, 1024) 0           conv4_block1_out[0][0]           \n",
      "                                                                 conv4_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_out (Activation)   (None, 14, 14, 1024) 0           conv4_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_relu (Activation (None, 14, 14, 256)  0           conv4_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_relu (Activation (None, 14, 14, 256)  0           conv4_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_add (Add)          (None, 14, 14, 1024) 0           conv4_block2_out[0][0]           \n",
      "                                                                 conv4_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_out (Activation)   (None, 14, 14, 1024) 0           conv4_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_relu (Activation (None, 14, 14, 256)  0           conv4_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_relu (Activation (None, 14, 14, 256)  0           conv4_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_add (Add)          (None, 14, 14, 1024) 0           conv4_block3_out[0][0]           \n",
      "                                                                 conv4_block4_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_out (Activation)   (None, 14, 14, 1024) 0           conv4_block4_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_relu (Activation (None, 14, 14, 256)  0           conv4_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_relu (Activation (None, 14, 14, 256)  0           conv4_block5_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block5_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block5_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_add (Add)          (None, 14, 14, 1024) 0           conv4_block4_out[0][0]           \n",
      "                                                                 conv4_block5_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_out (Activation)   (None, 14, 14, 1024) 0           conv4_block5_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block5_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_relu (Activation (None, 14, 14, 256)  0           conv4_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_relu (Activation (None, 14, 14, 256)  0           conv4_block6_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block6_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block6_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_add (Add)          (None, 14, 14, 1024) 0           conv4_block5_out[0][0]           \n",
      "                                                                 conv4_block6_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_out (Activation)   (None, 14, 14, 1024) 0           conv4_block6_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_conv (Conv2D)    (None, 7, 7, 512)    524800      conv4_block6_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_relu (Activation (None, 7, 7, 512)    0           conv5_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_relu (Activation (None, 7, 7, 512)    0           conv5_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_conv (Conv2D)    (None, 7, 7, 2048)   2099200     conv4_block6_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_add (Add)          (None, 7, 7, 2048)   0           conv5_block1_0_bn[0][0]          \n",
      "                                                                 conv5_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_out (Activation)   (None, 7, 7, 2048)   0           conv5_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_conv (Conv2D)    (None, 7, 7, 512)    1049088     conv5_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_relu (Activation (None, 7, 7, 512)    0           conv5_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_relu (Activation (None, 7, 7, 512)    0           conv5_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_add (Add)          (None, 7, 7, 2048)   0           conv5_block1_out[0][0]           \n",
      "                                                                 conv5_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_out (Activation)   (None, 7, 7, 2048)   0           conv5_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_conv (Conv2D)    (None, 7, 7, 512)    1049088     conv5_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_relu (Activation (None, 7, 7, 512)    0           conv5_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_relu (Activation (None, 7, 7, 512)    0           conv5_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_add (Add)          (None, 7, 7, 2048)   0           conv5_block2_out[0][0]           \n",
      "                                                                 conv5_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_out (Activation)   (None, 7, 7, 2048)   0           conv5_block3_add[0][0]           \n",
      "==================================================================================================\n",
      "Total params: 23,587,712\n",
      "Trainable params: 0\n",
      "Non-trainable params: 23,587,712\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# BUILD THE BASE MODEL - RESNET50\n",
    "# do not include the FC layer at the top of network\n",
    "# and freeze the base model for transfer learning\n",
    "inputShape = (224,224,3)\n",
    "resnet50_model = ResNet50(weights='imagenet', include_top=False, input_shape=inputShape)\n",
    "resnet50_model.trainable = False #freeze the base model\n",
    "resnet50_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ADD NEW TRAINABLE LAYERS ON TOP TO BUILD THE FINAL MODEL\n",
    "from tensorflow.keras.layers.experimental.preprocessing import RandomContrast, RandomFlip\n",
    "\n",
    "inputs = Input(shape=(224,224,3))\n",
    "data_augmentation = Sequential([RandomFlip('horizontal'), RandomContrast(0.2)])\n",
    "\n",
    "x = preprocess_input(inputs)\n",
    "x = resnet50_model(x, training=False) #run in inference mode\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "outputs = Dense(7,activation='softmax')(x) #7 output classes\n",
    "model = Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_14 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
      "_________________________________________________________________\n",
      "tf.__operators__.getitem_4 ( (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "tf.nn.bias_add_4 (TFOpLambda (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "resnet50 (Functional)        (None, 7, 7, 2048)        23587712  \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_5 ( (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 7)                 14343     \n",
      "=================================================================\n",
      "Total params: 23,602,055\n",
      "Trainable params: 14,343\n",
      "Non-trainable params: 23,587,712\n",
      "_________________________________________________________________\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "# COMPILE THE NEW MODEL\n",
    "base_learning_rate = 0.0001\n",
    "model.compile(optimizer= Adam(learning_rate=base_learning_rate),\n",
    "              loss = SparseCategoricalCrossentropy(),\n",
    "              metrics = ['accuracy'])\n",
    "model.summary()\n",
    "print(len(model.trainable_variables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 12s 2s/step - loss: 1.4577 - accuracy: 0.4545\n",
      "Initial loss: 1.4577338695526123 accuracy: 0.4545454680919647\n",
      "Epoch 1/100\n",
      "9/9 [==============================] - 57s 6s/step - loss: 1.1468 - accuracy: 0.5955 - val_loss: 1.4461 - val_accuracy: 0.4545\n",
      "Epoch 2/100\n",
      "9/9 [==============================] - 54s 6s/step - loss: 1.1255 - accuracy: 0.6067 - val_loss: 1.4551 - val_accuracy: 0.4545\n",
      "Epoch 3/100\n",
      "9/9 [==============================] - 56s 6s/step - loss: 1.1194 - accuracy: 0.6142 - val_loss: 1.4593 - val_accuracy: 0.4394\n",
      "Epoch 4/100\n",
      "9/9 [==============================] - 59s 7s/step - loss: 1.1123 - accuracy: 0.6142 - val_loss: 1.4572 - val_accuracy: 0.4848\n",
      "Epoch 5/100\n",
      "9/9 [==============================] - 68s 8s/step - loss: 1.1065 - accuracy: 0.6067 - val_loss: 1.4604 - val_accuracy: 0.4697\n",
      "Epoch 6/100\n",
      "9/9 [==============================] - 59s 7s/step - loss: 1.0980 - accuracy: 0.6105 - val_loss: 1.4547 - val_accuracy: 0.4394\n",
      "Epoch 7/100\n",
      "9/9 [==============================] - 59s 7s/step - loss: 1.0925 - accuracy: 0.6217 - val_loss: 1.4511 - val_accuracy: 0.4394\n",
      "Epoch 8/100\n",
      "9/9 [==============================] - 60s 7s/step - loss: 1.0871 - accuracy: 0.6105 - val_loss: 1.4469 - val_accuracy: 0.4697\n",
      "Epoch 9/100\n",
      "9/9 [==============================] - 60s 7s/step - loss: 1.0807 - accuracy: 0.6180 - val_loss: 1.4449 - val_accuracy: 0.4394\n",
      "Epoch 10/100\n",
      "9/9 [==============================] - 61s 7s/step - loss: 1.0747 - accuracy: 0.6367 - val_loss: 1.4472 - val_accuracy: 0.4394\n",
      "Epoch 11/100\n",
      "9/9 [==============================] - 60s 7s/step - loss: 1.0691 - accuracy: 0.6330 - val_loss: 1.4513 - val_accuracy: 0.4394\n",
      "Epoch 12/100\n",
      "9/9 [==============================] - 60s 7s/step - loss: 1.0617 - accuracy: 0.6330 - val_loss: 1.4570 - val_accuracy: 0.4394\n",
      "Epoch 13/100\n",
      "9/9 [==============================] - 61s 7s/step - loss: 1.0575 - accuracy: 0.6404 - val_loss: 1.4567 - val_accuracy: 0.4545\n",
      "Epoch 14/100\n",
      "9/9 [==============================] - 61s 7s/step - loss: 1.0518 - accuracy: 0.6330 - val_loss: 1.4600 - val_accuracy: 0.4394\n",
      "Epoch 15/100\n",
      "9/9 [==============================] - 61s 7s/step - loss: 1.0467 - accuracy: 0.6479 - val_loss: 1.4634 - val_accuracy: 0.4394\n",
      "Epoch 16/100\n",
      "9/9 [==============================] - 61s 7s/step - loss: 1.0395 - accuracy: 0.6404 - val_loss: 1.4594 - val_accuracy: 0.4242\n",
      "Epoch 17/100\n",
      "9/9 [==============================] - 61s 7s/step - loss: 1.0353 - accuracy: 0.6367 - val_loss: 1.4531 - val_accuracy: 0.4545\n",
      "Epoch 18/100\n",
      "9/9 [==============================] - 60s 7s/step - loss: 1.0299 - accuracy: 0.6517 - val_loss: 1.4546 - val_accuracy: 0.4545\n",
      "Epoch 19/100\n",
      "9/9 [==============================] - 61s 7s/step - loss: 1.0225 - accuracy: 0.6629 - val_loss: 1.4630 - val_accuracy: 0.4545\n",
      "Epoch 20/100\n",
      "9/9 [==============================] - 60s 7s/step - loss: 1.0199 - accuracy: 0.6667 - val_loss: 1.4655 - val_accuracy: 0.4545\n",
      "Epoch 21/100\n",
      "9/9 [==============================] - 63s 7s/step - loss: 1.0147 - accuracy: 0.6667 - val_loss: 1.4629 - val_accuracy: 0.4394\n",
      "Epoch 22/100\n",
      "9/9 [==============================] - 69s 8s/step - loss: 1.0088 - accuracy: 0.6517 - val_loss: 1.4641 - val_accuracy: 0.4394\n",
      "Epoch 23/100\n",
      "9/9 [==============================] - 65s 7s/step - loss: 1.0047 - accuracy: 0.6442 - val_loss: 1.4539 - val_accuracy: 0.4394\n",
      "Epoch 24/100\n",
      "9/9 [==============================] - 61s 7s/step - loss: 0.9999 - accuracy: 0.6479 - val_loss: 1.4579 - val_accuracy: 0.4394\n",
      "Epoch 25/100\n",
      "9/9 [==============================] - 61s 7s/step - loss: 0.9948 - accuracy: 0.6479 - val_loss: 1.4569 - val_accuracy: 0.4091\n",
      "Epoch 26/100\n",
      "9/9 [==============================] - 61s 7s/step - loss: 0.9897 - accuracy: 0.6742 - val_loss: 1.4580 - val_accuracy: 0.4394\n",
      "Epoch 27/100\n",
      "9/9 [==============================] - 61s 7s/step - loss: 0.9871 - accuracy: 0.6816 - val_loss: 1.4609 - val_accuracy: 0.4545\n",
      "Epoch 28/100\n",
      "9/9 [==============================] - 62s 7s/step - loss: 0.9819 - accuracy: 0.6742 - val_loss: 1.4586 - val_accuracy: 0.4394\n",
      "Epoch 29/100\n",
      "9/9 [==============================] - 61s 7s/step - loss: 0.9773 - accuracy: 0.6891 - val_loss: 1.4522 - val_accuracy: 0.4242\n",
      "Epoch 30/100\n",
      "9/9 [==============================] - 62s 7s/step - loss: 0.9721 - accuracy: 0.6779 - val_loss: 1.4536 - val_accuracy: 0.4242\n",
      "Epoch 31/100\n",
      "9/9 [==============================] - 64s 7s/step - loss: 0.9667 - accuracy: 0.6816 - val_loss: 1.4583 - val_accuracy: 0.4242\n",
      "Epoch 32/100\n",
      "9/9 [==============================] - 61s 7s/step - loss: 0.9618 - accuracy: 0.6816 - val_loss: 1.4655 - val_accuracy: 0.4242\n",
      "Epoch 33/100\n",
      "9/9 [==============================] - 62s 7s/step - loss: 0.9598 - accuracy: 0.6854 - val_loss: 1.4697 - val_accuracy: 0.4242\n",
      "Epoch 34/100\n",
      "9/9 [==============================] - 62s 7s/step - loss: 0.9550 - accuracy: 0.6891 - val_loss: 1.4575 - val_accuracy: 0.4242\n",
      "Epoch 35/100\n",
      "9/9 [==============================] - 62s 7s/step - loss: 0.9535 - accuracy: 0.6816 - val_loss: 1.4610 - val_accuracy: 0.4242\n",
      "Epoch 36/100\n",
      "9/9 [==============================] - 62s 7s/step - loss: 0.9460 - accuracy: 0.6816 - val_loss: 1.4611 - val_accuracy: 0.4394\n",
      "Epoch 37/100\n",
      "9/9 [==============================] - 62s 7s/step - loss: 0.9422 - accuracy: 0.6929 - val_loss: 1.4679 - val_accuracy: 0.4242\n",
      "Epoch 38/100\n",
      "9/9 [==============================] - 62s 7s/step - loss: 0.9377 - accuracy: 0.6966 - val_loss: 1.4662 - val_accuracy: 0.4394\n",
      "Epoch 39/100\n",
      "9/9 [==============================] - 62s 7s/step - loss: 0.9341 - accuracy: 0.7004 - val_loss: 1.4635 - val_accuracy: 0.4394\n",
      "Epoch 40/100\n",
      "9/9 [==============================] - 63s 7s/step - loss: 0.9313 - accuracy: 0.6891 - val_loss: 1.4600 - val_accuracy: 0.4545\n",
      "Epoch 41/100\n",
      "9/9 [==============================] - 62s 7s/step - loss: 0.9276 - accuracy: 0.6929 - val_loss: 1.4663 - val_accuracy: 0.4394\n",
      "Epoch 42/100\n",
      "9/9 [==============================] - 62s 7s/step - loss: 0.9230 - accuracy: 0.6929 - val_loss: 1.4712 - val_accuracy: 0.4394\n",
      "Epoch 43/100\n",
      "9/9 [==============================] - 62s 7s/step - loss: 0.9183 - accuracy: 0.7004 - val_loss: 1.4679 - val_accuracy: 0.4394\n",
      "Epoch 44/100\n",
      "9/9 [==============================] - 61s 7s/step - loss: 0.9148 - accuracy: 0.6854 - val_loss: 1.4691 - val_accuracy: 0.4697\n",
      "Epoch 45/100\n",
      "9/9 [==============================] - 62s 7s/step - loss: 0.9102 - accuracy: 0.7004 - val_loss: 1.4661 - val_accuracy: 0.4848\n",
      "Epoch 46/100\n",
      "9/9 [==============================] - 59s 7s/step - loss: 0.9056 - accuracy: 0.7116 - val_loss: 1.4662 - val_accuracy: 0.4697\n",
      "Epoch 47/100\n",
      "9/9 [==============================] - 54s 6s/step - loss: 0.9041 - accuracy: 0.7041 - val_loss: 1.4659 - val_accuracy: 0.4394\n",
      "Epoch 48/100\n",
      "9/9 [==============================] - 55s 6s/step - loss: 0.8981 - accuracy: 0.7154 - val_loss: 1.4635 - val_accuracy: 0.4394\n",
      "Epoch 49/100\n",
      "9/9 [==============================] - 55s 6s/step - loss: 0.8966 - accuracy: 0.7041 - val_loss: 1.4578 - val_accuracy: 0.4545\n",
      "Epoch 50/100\n",
      "9/9 [==============================] - 55s 6s/step - loss: 0.8936 - accuracy: 0.7116 - val_loss: 1.4553 - val_accuracy: 0.4697\n",
      "Epoch 51/100\n",
      "9/9 [==============================] - 55s 6s/step - loss: 0.8901 - accuracy: 0.7079 - val_loss: 1.4651 - val_accuracy: 0.4697\n",
      "Epoch 52/100\n",
      "9/9 [==============================] - 55s 6s/step - loss: 0.8879 - accuracy: 0.7228 - val_loss: 1.4759 - val_accuracy: 0.4545\n",
      "Epoch 53/100\n",
      "9/9 [==============================] - 54s 6s/step - loss: 0.8851 - accuracy: 0.7191 - val_loss: 1.4718 - val_accuracy: 0.4545\n",
      "Epoch 54/100\n",
      "9/9 [==============================] - 55s 6s/step - loss: 0.8790 - accuracy: 0.7266 - val_loss: 1.4567 - val_accuracy: 0.4545\n",
      "Epoch 55/100\n",
      "9/9 [==============================] - 55s 6s/step - loss: 0.8757 - accuracy: 0.7341 - val_loss: 1.4514 - val_accuracy: 0.4848\n",
      "Epoch 56/100\n",
      "9/9 [==============================] - 54s 6s/step - loss: 0.8723 - accuracy: 0.7191 - val_loss: 1.4550 - val_accuracy: 0.4697\n",
      "Epoch 57/100\n",
      "9/9 [==============================] - 54s 6s/step - loss: 0.8685 - accuracy: 0.7228 - val_loss: 1.4604 - val_accuracy: 0.4697\n",
      "Epoch 58/100\n",
      "9/9 [==============================] - 55s 6s/step - loss: 0.8677 - accuracy: 0.7341 - val_loss: 1.4647 - val_accuracy: 0.4848\n",
      "Epoch 59/100\n",
      "9/9 [==============================] - 54s 6s/step - loss: 0.8638 - accuracy: 0.7303 - val_loss: 1.4720 - val_accuracy: 0.4545\n",
      "Epoch 60/100\n",
      "9/9 [==============================] - 54s 6s/step - loss: 0.8596 - accuracy: 0.7341 - val_loss: 1.4736 - val_accuracy: 0.4394\n",
      "Epoch 61/100\n",
      "9/9 [==============================] - 55s 6s/step - loss: 0.8570 - accuracy: 0.7303 - val_loss: 1.4732 - val_accuracy: 0.4394\n",
      "Epoch 62/100\n",
      "9/9 [==============================] - 54s 6s/step - loss: 0.8527 - accuracy: 0.7228 - val_loss: 1.4631 - val_accuracy: 0.4545\n",
      "Epoch 63/100\n",
      "9/9 [==============================] - 54s 6s/step - loss: 0.8514 - accuracy: 0.7228 - val_loss: 1.4605 - val_accuracy: 0.4697\n",
      "Epoch 64/100\n",
      "9/9 [==============================] - 54s 6s/step - loss: 0.8465 - accuracy: 0.7228 - val_loss: 1.4636 - val_accuracy: 0.4848\n",
      "Epoch 65/100\n",
      "9/9 [==============================] - 60s 7s/step - loss: 0.8434 - accuracy: 0.7341 - val_loss: 1.4665 - val_accuracy: 0.4848\n",
      "Epoch 66/100\n",
      "9/9 [==============================] - 56s 6s/step - loss: 0.8408 - accuracy: 0.7491 - val_loss: 1.4642 - val_accuracy: 0.4848\n",
      "Epoch 67/100\n",
      "9/9 [==============================] - 54s 6s/step - loss: 0.8379 - accuracy: 0.7416 - val_loss: 1.4677 - val_accuracy: 0.4848\n",
      "Epoch 68/100\n",
      "9/9 [==============================] - 55s 6s/step - loss: 0.8343 - accuracy: 0.7378 - val_loss: 1.4652 - val_accuracy: 0.4848\n",
      "Epoch 69/100\n",
      "9/9 [==============================] - 55s 6s/step - loss: 0.8311 - accuracy: 0.7416 - val_loss: 1.4674 - val_accuracy: 0.4545\n",
      "Epoch 70/100\n",
      "9/9 [==============================] - 54s 6s/step - loss: 0.8274 - accuracy: 0.7416 - val_loss: 1.4692 - val_accuracy: 0.4545\n",
      "Epoch 71/100\n",
      "9/9 [==============================] - 55s 6s/step - loss: 0.8269 - accuracy: 0.7341 - val_loss: 1.4749 - val_accuracy: 0.4394\n",
      "Epoch 72/100\n",
      "9/9 [==============================] - 55s 6s/step - loss: 0.8231 - accuracy: 0.7416 - val_loss: 1.4671 - val_accuracy: 0.4697\n",
      "Epoch 73/100\n",
      "9/9 [==============================] - 55s 6s/step - loss: 0.8208 - accuracy: 0.7453 - val_loss: 1.4703 - val_accuracy: 0.4848\n",
      "Epoch 74/100\n",
      "9/9 [==============================] - 54s 6s/step - loss: 0.8178 - accuracy: 0.7341 - val_loss: 1.4681 - val_accuracy: 0.4848\n",
      "Epoch 75/100\n",
      "9/9 [==============================] - 54s 6s/step - loss: 0.8143 - accuracy: 0.7453 - val_loss: 1.4697 - val_accuracy: 0.4545\n",
      "Epoch 76/100\n",
      "9/9 [==============================] - 54s 6s/step - loss: 0.8121 - accuracy: 0.7491 - val_loss: 1.4715 - val_accuracy: 0.4697\n",
      "Epoch 77/100\n",
      "9/9 [==============================] - 54s 6s/step - loss: 0.8103 - accuracy: 0.7378 - val_loss: 1.4771 - val_accuracy: 0.4545\n",
      "Epoch 78/100\n",
      "9/9 [==============================] - 55s 6s/step - loss: 0.8077 - accuracy: 0.7528 - val_loss: 1.4716 - val_accuracy: 0.4697\n",
      "Epoch 79/100\n",
      "9/9 [==============================] - 54s 6s/step - loss: 0.8035 - accuracy: 0.7566 - val_loss: 1.4784 - val_accuracy: 0.4848\n",
      "Epoch 80/100\n",
      "9/9 [==============================] - 54s 6s/step - loss: 0.8002 - accuracy: 0.7491 - val_loss: 1.4857 - val_accuracy: 0.4545\n",
      "Epoch 81/100\n",
      "9/9 [==============================] - 54s 6s/step - loss: 0.7975 - accuracy: 0.7603 - val_loss: 1.4742 - val_accuracy: 0.4545\n",
      "Epoch 82/100\n",
      "9/9 [==============================] - 55s 6s/step - loss: 0.7963 - accuracy: 0.7640 - val_loss: 1.4750 - val_accuracy: 0.4697\n",
      "Epoch 83/100\n",
      "9/9 [==============================] - 54s 6s/step - loss: 0.7932 - accuracy: 0.7566 - val_loss: 1.4836 - val_accuracy: 0.4848\n",
      "Epoch 84/100\n",
      "9/9 [==============================] - 54s 6s/step - loss: 0.7904 - accuracy: 0.7491 - val_loss: 1.4860 - val_accuracy: 0.4697\n",
      "Epoch 85/100\n",
      "9/9 [==============================] - 55s 6s/step - loss: 0.7864 - accuracy: 0.7453 - val_loss: 1.4882 - val_accuracy: 0.4697\n",
      "Epoch 86/100\n",
      "9/9 [==============================] - 55s 6s/step - loss: 0.7874 - accuracy: 0.7453 - val_loss: 1.4865 - val_accuracy: 0.4545\n",
      "Epoch 87/100\n",
      "9/9 [==============================] - 54s 6s/step - loss: 0.7815 - accuracy: 0.7528 - val_loss: 1.4855 - val_accuracy: 0.4697\n",
      "Epoch 88/100\n",
      "9/9 [==============================] - 54s 6s/step - loss: 0.7789 - accuracy: 0.7491 - val_loss: 1.4796 - val_accuracy: 0.4697\n",
      "Epoch 89/100\n",
      "9/9 [==============================] - 54s 6s/step - loss: 0.7766 - accuracy: 0.7566 - val_loss: 1.4819 - val_accuracy: 0.4697\n",
      "Epoch 90/100\n",
      "9/9 [==============================] - 54s 6s/step - loss: 0.7738 - accuracy: 0.7566 - val_loss: 1.4821 - val_accuracy: 0.4697\n",
      "Epoch 91/100\n",
      "9/9 [==============================] - 54s 6s/step - loss: 0.7726 - accuracy: 0.7640 - val_loss: 1.4960 - val_accuracy: 0.4545\n",
      "Epoch 92/100\n",
      "9/9 [==============================] - 54s 6s/step - loss: 0.7702 - accuracy: 0.7678 - val_loss: 1.4884 - val_accuracy: 0.4545\n",
      "Epoch 93/100\n",
      "9/9 [==============================] - 54s 6s/step - loss: 0.7665 - accuracy: 0.7640 - val_loss: 1.4905 - val_accuracy: 0.4697\n",
      "Epoch 94/100\n",
      "9/9 [==============================] - 54s 6s/step - loss: 0.7645 - accuracy: 0.7678 - val_loss: 1.4802 - val_accuracy: 0.4697\n",
      "Epoch 95/100\n",
      "9/9 [==============================] - 55s 6s/step - loss: 0.7638 - accuracy: 0.7678 - val_loss: 1.4754 - val_accuracy: 0.4545\n",
      "Epoch 96/100\n",
      "9/9 [==============================] - 55s 6s/step - loss: 0.7598 - accuracy: 0.7715 - val_loss: 1.4721 - val_accuracy: 0.4848\n",
      "Epoch 97/100\n",
      "9/9 [==============================] - 54s 6s/step - loss: 0.7569 - accuracy: 0.7678 - val_loss: 1.4795 - val_accuracy: 0.4848\n",
      "Epoch 98/100\n",
      "9/9 [==============================] - 55s 6s/step - loss: 0.7550 - accuracy: 0.7790 - val_loss: 1.4792 - val_accuracy: 0.4697\n",
      "Epoch 99/100\n",
      "9/9 [==============================] - 54s 6s/step - loss: 0.7524 - accuracy: 0.7678 - val_loss: 1.4778 - val_accuracy: 0.5000\n",
      "Epoch 100/100\n",
      "9/9 [==============================] - 54s 6s/step - loss: 0.7499 - accuracy: 0.7790 - val_loss: 1.4760 - val_accuracy: 0.5000\n"
     ]
    }
   ],
   "source": [
    "# TRAIN NEW MODEL ON MICRO-EXPRESSION DATASET\n",
    "# check initial accuracy before training\n",
    "loss0, accuracy0 = model.evaluate(me_val_dataset)\n",
    "print('Initial loss: {} accuracy: {}'.format(loss0, accuracy0))\n",
    "\n",
    "# train on new (Macro-expression) dataset and print accuracy after training\n",
    "history = model.fit(me_train_dataset, epochs=100, validation_data= me_val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "9/9 [==============================] - 59s 6s/step - loss: 2.1665 - accuracy: 0.1873 - val_loss: 2.1302 - val_accuracy: 0.2121\n",
      "Epoch 2/20\n",
      "9/9 [==============================] - 58s 7s/step - loss: 2.1389 - accuracy: 0.1873 - val_loss: 2.1089 - val_accuracy: 0.1970\n",
      "Epoch 3/20\n",
      "9/9 [==============================] - 57s 6s/step - loss: 2.1147 - accuracy: 0.1873 - val_loss: 2.0897 - val_accuracy: 0.1970\n",
      "Epoch 4/20\n",
      "9/9 [==============================] - 65s 7s/step - loss: 2.0904 - accuracy: 0.1910 - val_loss: 2.0728 - val_accuracy: 0.2121\n",
      "Epoch 5/20\n",
      "9/9 [==============================] - 67s 7s/step - loss: 2.0693 - accuracy: 0.1873 - val_loss: 2.0564 - val_accuracy: 0.2121\n",
      "Epoch 6/20\n",
      "9/9 [==============================] - 61s 7s/step - loss: 2.0498 - accuracy: 0.1873 - val_loss: 2.0415 - val_accuracy: 0.1970\n",
      "Epoch 7/20\n",
      "9/9 [==============================] - 58s 6s/step - loss: 2.0313 - accuracy: 0.1873 - val_loss: 2.0284 - val_accuracy: 0.1970\n",
      "Epoch 8/20\n",
      "9/9 [==============================] - 58s 6s/step - loss: 2.0127 - accuracy: 0.1873 - val_loss: 2.0172 - val_accuracy: 0.1970\n",
      "Epoch 9/20\n",
      "9/9 [==============================] - 58s 6s/step - loss: 1.9979 - accuracy: 0.1985 - val_loss: 2.0054 - val_accuracy: 0.1970\n",
      "Epoch 10/20\n",
      "9/9 [==============================] - 62s 7s/step - loss: 1.9825 - accuracy: 0.2060 - val_loss: 1.9938 - val_accuracy: 0.1970\n",
      "Epoch 11/20\n",
      "9/9 [==============================] - 61s 7s/step - loss: 1.9689 - accuracy: 0.2060 - val_loss: 1.9840 - val_accuracy: 0.1970\n",
      "Epoch 12/20\n",
      "9/9 [==============================] - 61s 7s/step - loss: 1.9545 - accuracy: 0.2022 - val_loss: 1.9751 - val_accuracy: 0.1970\n",
      "Epoch 13/20\n",
      "9/9 [==============================] - 68s 8s/step - loss: 1.9431 - accuracy: 0.2135 - val_loss: 1.9675 - val_accuracy: 0.1818\n",
      "Epoch 14/20\n",
      "9/9 [==============================] - 60s 7s/step - loss: 1.9322 - accuracy: 0.2060 - val_loss: 1.9604 - val_accuracy: 0.1818\n",
      "Epoch 15/20\n",
      "9/9 [==============================] - 58s 6s/step - loss: 1.9209 - accuracy: 0.1985 - val_loss: 1.9538 - val_accuracy: 0.1818\n",
      "Epoch 16/20\n",
      "9/9 [==============================] - 60s 7s/step - loss: 1.9115 - accuracy: 0.1985 - val_loss: 1.9475 - val_accuracy: 0.1818\n",
      "Epoch 17/20\n",
      "9/9 [==============================] - 59s 7s/step - loss: 1.9018 - accuracy: 0.1985 - val_loss: 1.9420 - val_accuracy: 0.1818\n",
      "Epoch 18/20\n",
      "9/9 [==============================] - 55s 6s/step - loss: 1.8926 - accuracy: 0.2022 - val_loss: 1.9365 - val_accuracy: 0.1818\n",
      "Epoch 19/20\n",
      "9/9 [==============================] - 54s 6s/step - loss: 1.8844 - accuracy: 0.1873 - val_loss: 1.9315 - val_accuracy: 0.1818\n",
      "Epoch 20/20\n",
      "9/9 [==============================] - 54s 6s/step - loss: 1.8757 - accuracy: 0.1948 - val_loss: 1.9271 - val_accuracy: 0.1818\n"
     ]
    }
   ],
   "source": [
    "# MODEL IS OVERFITTING (TRAINING ACCURACY GETTING HIGHER WHILE VALIDATION ACCURACY PLATEAUED)\n",
    "\n",
    "from tensorflow.keras.layers.experimental.preprocessing import RandomContrast, RandomFlip\n",
    "\n",
    "inputs = Input(shape=(224,224,3))\n",
    "data_augmentation = Sequential([RandomFlip('horizontal'), RandomContrast(0.2)])\n",
    "\n",
    "x = data_augmentation(inputs) #add data augmentation step\n",
    "x = preprocess_input(inputs)\n",
    "x = resnet50_model(x, training=False) #run in inference mode\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "outputs = Dense(7,activation='softmax')(x) #7 output classes\n",
    "model2 = Model(inputs, outputs)\n",
    "\n",
    "base_learning_rate = 0.00001 #reduce LR\n",
    "model2.compile(optimizer= Adam(learning_rate=base_learning_rate),\n",
    "              loss = SparseCategoricalCrossentropy(),\n",
    "              metrics = ['accuracy'])\n",
    "history2 = model2.fit(me_train_dataset, epochs=20, validation_data= me_val_dataset)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9966458c6ad74b8bc08c1c30471a4ad47794339d9867a51d09ce220173850fd9"
  },
  "kernelspec": {
   "display_name": "Python 3.9.1 64-bit ('effNetVenv': venv)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
